{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b525a08a",
   "metadata": {},
   "source": [
    "# Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa35ba",
   "metadata": {},
   "source": [
    "Зачет:\n",
    "\n",
    "Обучить деттектор на 2 класса ```cat``` и  ```horse``` на базе датасета pascal VOC 2007, в качестве детектора предлагается взять  fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ff839",
   "metadata": {},
   "source": [
    "Экзамен задача на выбор :\n",
    "\n",
    "1. Применить к обученному детектору из зачета прунинг сверточных слоев L2 и дообучить модель после прунинга\n",
    "2. Обучить модель по принципу RL игре Pong-v0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68237c1",
   "metadata": {},
   "source": [
    "Зачет принимается индивидуально\n",
    "\n",
    "Экзамен можно сдавать по группам не более 3-х человек\n",
    "\n",
    "В итоге нужно прислать тетрадку с обучением и веса моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac660f5",
   "metadata": {},
   "source": [
    "В данной работе продемонстрирую первую стратегию - Однократное прореживание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b4b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "#train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7432c4",
   "metadata": {},
   "source": [
    "### 1.2 Импортирование модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b092b44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-29 00:07:46] INFO (numexpr.utils/MainThread) NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                       \n",
    "import torch                       \n",
    "import torchvision                       \n",
    "from torch import nn                       \n",
    "from torch.autograd import Variable                       \n",
    "from torchvision.datasets import MNIST \n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T                      \n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from nni.algorithms.compression.pytorch.pruning import L1FilterPruner\n",
    "from nni.algorithms.compression.pytorch.pruning import L2FilterPruner\n",
    "from nni.compression.pytorch import ModelSpeedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffda36",
   "metadata": {},
   "source": [
    "### 1.3 Воспроизводимое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7679ece",
   "metadata": {},
   "source": [
    "Для того, чтобы делать А-Б тесты и постепенно улучшать процесс обучения нейронной сети, необходимо позаботиться о том, чтобы результат обучения воспроизводился от запуска к запуску. Поскольку при обучении нейронных сетей часто используются псевдослучайные числа, необходимо, чтобы генераторы случайных чисел выдавали одни и те же последовательности от запуска к запуску. Кроме того, необходимо переключить CUDA в детерминированный режим. Это требование уменьшает скорость выполнения программы, зато результаты вычислений становятся воспроизводимыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0729ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f201e",
   "metadata": {},
   "source": [
    "### 2.1 Определим функции для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129c58c",
   "metadata": {},
   "source": [
    "Класс ```MetricMonitor``` вспомогательный, который агригирует значения по каждому новому batch и выводит статистику онлайн накопительным образом. Это позволяет во время обучения мониторить изменение метрик онлайн.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824509b",
   "metadata": {},
   "source": [
    "Функция ```train``` отвечает за обучение. \n",
    "\n",
    "При этом, функция универсальная, тк работает с входными переменными: \n",
    "\n",
    "датасет ```train_loader```, \n",
    "\n",
    "модель ```model```, \n",
    "\n",
    "функцию ошибок ```criterion```, \n",
    "\n",
    "функцию оптимизации ```optimizer```, \n",
    "\n",
    "число эпох для обучения ```epochs```, \n",
    "\n",
    "params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9139b",
   "metadata": {},
   "source": [
    "Функция ```validate```  отчечает за прогон данных на валидационной выборке ```val_loader``` и так же универсальна, тк большую часть переменных получает извне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2727e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "def train(train_loader, model, criterion, optimizer, epochs, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    eterator = tqdm(train_loader)\n",
    "    for i, data in enumerate(eterator, start=1):\n",
    "        \n",
    "        image, label = data\n",
    "        image = image.to(params[\"device\"], non_blocking=True)\n",
    "        label = label.to(params[\"device\"], non_blocking=True)\n",
    "        #print(type(image))\n",
    "        output = model(image)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        loss = criterion(output, label)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", pred.eq(label.view_as(pred)).sum().item()/pred.shape[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        eterator.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epochs, metric_monitor=metric_monitor)\n",
    "        )\n",
    "        \n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    eterator = tqdm(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(eterator, start=1):\n",
    "            image = image.to(params[\"device\"], non_blocking=True)\n",
    "            label = label.to(params[\"device\"], non_blocking=True)\n",
    "            output = model(image)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            loss = criterion(output, label)\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", pred.eq(label.view_as(pred)).sum().item()/pred.shape[0])\n",
    "            eterator.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )\n",
    "    return metric_monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c561e",
   "metadata": {},
   "source": [
    "### 2.2 Определим функцию паплайна для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aece8a7",
   "metadata": {},
   "source": [
    "Функция ```train_and_validate``` инициализирует train и valid датасет, задает функцию потерь и фунцию оптимизации, затем последовательно в Эпохе вызывает ранее определенную функцию обучения и функцию валидации.\n",
    "Обращаю внимание, что этот паплайн возвращает в качестве результата обученную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07696566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_dataset, val_dataset, params):    \n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=params[\"batch_size\"],\n",
    "                              num_workers=params[\"num_workers\"],\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                              batch_size=params[\"batch_size\"],\n",
    "                              num_workers=params[\"num_workers\"],\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True)\n",
    "    \n",
    "    criterion =  nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"])\n",
    "    #print(params[\"epochs\"] + 1)\n",
    "    for epoch in range(1, params[\"epochs\"] + 1):\n",
    "        train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "        validate(val_loader, model, criterion, epoch, params)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed196e",
   "metadata": {},
   "source": [
    "### 3.1 Инициализация датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7584c",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы не будем писать своих датасетов, а будем использовать те, что имеются в наличии во вспомогательной библиотеке `torchvision`. Нас будет интересовать датасет `Cifar10` (10 классов).\n",
    "\n",
    "1. Изучите интерфейс класса `torchvision.datasets.CIFAR10`. Посмотрите, какими параметрами можно влиять этот датасет.\n",
    "\n",
    "2. Инициализируйте тренировочный и тестовый датасеты (`torchvision.datasets.CIFAR10`). \n",
    "\n",
    "3. В конструкторе используйте следующие параметры:\n",
    "    * аугментации из `torchvision.transforms`:\n",
    "        * `T.ToTensor()`\n",
    "        * `T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),`\n",
    "\n",
    "    * `root` -- любой на Ваш вкус\n",
    "    * проанализируйте и выставьте остальные аргументы так, как вам кажется правильнее. Не забывайте, что перемешивать датасет имеет смысл для тренировочной выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9f3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b2d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#px = 256\n",
    "#MemoryError: Unable to allocate 1.50 MiB for an array with shape (3, 256, 256) and data type object\n",
    "px = 32\n",
    "preprocess = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    T.Resize((px, px)),\n",
    "    #T.Lambda(lambda x: torch.reshape(x,(32, 32, 3)))\n",
    "    # torch.reshape меняет num_channels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8ab7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_t = CIFAR10(root=\"./Cifar\",train = True, transform = preprocess, download=True)\n",
    "#data_v = CIFAR10(root=\"./Cifar\",train = False, transform = preprocess, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4310250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: VOC\\VOCtrainval_06-Nov-2007.tar\n",
      "Extracting VOC\\VOCtrainval_06-Nov-2007.tar to VOC\n",
      "Using downloaded and verified file: VOC\\VOCtrainval_06-Nov-2007.tar\n",
      "Extracting VOC\\VOCtrainval_06-Nov-2007.tar to VOC\n"
     ]
    }
   ],
   "source": [
    "data_train = torchvision.datasets.VOCDetection(root=\"VOC\", year = '2007', image_set = 'train' , download=True, transform = preprocess)\n",
    "data_test = torchvision.datasets.VOCDetection(root=\"VOC\", year = '2007', image_set = 'val' , download=True, transform = preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5799ecbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.transforms.functional.get_image_num_channels(data_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd55e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40cab920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91e9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_t.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01a7e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(data_t.data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b29601c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_t.data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f778050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc2102f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(data_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46724cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_reshape = [(torch.reshape(data_train[i][0], (32, 32, 3)), i) for i in range(len(data_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe566a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test_reshape = [(torch.reshape(data_test[i][0], (32, 32, 3)), i) for i in range(len(data_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56fc4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data_t[3]), type(data_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33173036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data_train_reshape[3]), type(data_train_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a07e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_reshape.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3cad464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acf941b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(data_train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "697b31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_train.data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3f54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e7d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cce80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01b0ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d084e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_train[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd854b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_train[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa299392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train[17][1]['annotation']['object'][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdb461c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(data_t[1])\n",
    "#data_t[1].count, data_t[1].index\n",
    "\n",
    "#data_t[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280f918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e07e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp/ipykernel_11272/3520638920.py:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_train_conv=np.array(arr_train)\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp/ipykernel_11272/3520638920.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_train_conv=np.array(arr_train)\n"
     ]
    }
   ],
   "source": [
    "#data_train_conv = np.empty([len(data_train), 2])\n",
    "arr_train = []\n",
    "for i in range(len(data_train)):\n",
    "    #data = data_train[i][0]\n",
    "    if data_train[i][1]['annotation']['object'][0]['name'] == 'cat':\n",
    "        label = 0\n",
    "    elif data_train[i][1]['annotation']['object'][0]['name'] == 'horse':\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 3\n",
    "    #ValueError: only one element tensors can be converted to Python scalars\n",
    "    #data_train_conv[i][0] = data_train[i][0]\n",
    "    #data_train_conv[i][1] = label\n",
    "    tup = (data_train[i][0], label)\n",
    "    arr_train.append(tup)\n",
    "data_train_conv=np.array(arr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b205d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_conv=np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f5bfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2952d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53599c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp/ipykernel_11272/433263208.py:12: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_test_conv=np.array(arr_test, dtype=object)\n"
     ]
    }
   ],
   "source": [
    "arr_test=[]\n",
    "for i in range(len(data_test)):\n",
    "    #data = data_train[i][0]\n",
    "    if data_test[i][1]['annotation']['object'][0]['name'] == 'cat':\n",
    "        label = 0\n",
    "    elif data_test[i][1]['annotation']['object'][0]['name'] == 'horse':\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 3\n",
    "    tup = (data_test[i][0], label)\n",
    "    arr_test.append(tup)\n",
    "data_test_conv=np.array(arr_test, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ded62b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, int)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train_conv[0][0]), type(data_train_conv[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142c628",
   "metadata": {},
   "source": [
    "**По итогу получаем 3 класса:**\n",
    "\n",
    "0. cat\n",
    "1. horse\n",
    "2. not(cat or horse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cdc52",
   "metadata": {},
   "source": [
    "### 4.1 Проведем файн-тюнинг модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692715b",
   "metadata": {},
   "source": [
    "Для скорости обучения возьмем стандартную предобученную легкую модель ResNet18 из библиотеки ```torchvision```. Нам потребуется изменить последний линейный слой ```fc``` на слой с 10 ответами, аналогично ответам в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b39c998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07f53207",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": 8,\n",
    "    \"epochs\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caa2a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained= True)\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "model = model.to(params[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f3c7f",
   "metadata": {},
   "source": [
    "Зададим прочие параметры обучения в объект типа dict ```params```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4ee3b",
   "metadata": {},
   "source": [
    "И запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7aefd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = train_and_validate(model, data_train, data_test, params)\n",
    "#TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f306b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtr = T.Compose(data_train)\n",
    "#dts = T.Compose(data_test)\n",
    "#model = train_and_validate(model, dtr, dts, params)\n",
    "#TypeError: object of type 'Compose' has no len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25f392c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data_t), type(data_train_conv), type(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eda41ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(data_t[0]),type(data_t[1]))\n",
    "#print(type(data_train_conv[0]),type(data_train_conv[1]))\n",
    "#print(type(arr[0]),type(arr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1b8487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_conv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0fa7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(type(data_t[0][0]),type(data_t[1][1])))\n",
    "#print(type(type(data_train_conv[0][0]),type(data_train_conv[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5890be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PicklingError: Can't pickle <function <lambda> at 0x00000247817AF0D0>: attribute lookup <lambda> on __main__ failed\n",
    "#model = train_and_validate(model, data_train, data_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "216fcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuntimeError: Given groups=1, \n",
    "# weight of size [64, 3, 7, 7], \n",
    "# expected input[128, 32, 32, 3] \n",
    "# to have 3 channels, but got 32 channels instead\n",
    "#model = train_and_validate(model, arr_train, arr_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df7f3581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 1.959 | Accuracy: 0.425: 100%|█████████████████████████████| 20/20 [00:44<00:00,  2.24s/it]\n",
      "Epoch: 1. Validation. Loss: 1.816 | Accuracy: 0.639: 100%|█████████████████████████████| 20/20 [00:13<00:00,  1.53it/s]\n",
      "Epoch: 2. Train.      Loss: 0.791 | Accuracy: 0.901: 100%|█████████████████████████████| 20/20 [00:45<00:00,  2.26s/it]\n",
      "Epoch: 2. Validation. Loss: 0.763 | Accuracy: 0.870: 100%|█████████████████████████████| 20/20 [00:12<00:00,  1.55it/s]\n",
      "Epoch: 3. Train.      Loss: 0.329 | Accuracy: 0.954: 100%|█████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]\n",
      "Epoch: 3. Validation. Loss: 0.547 | Accuracy: 0.881: 100%|█████████████████████████████| 20/20 [00:12<00:00,  1.57it/s]\n",
      "Epoch: 4. Train.      Loss: 0.166 | Accuracy: 0.978: 100%|█████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]\n",
      "Epoch: 4. Validation. Loss: 0.516 | Accuracy: 0.881: 100%|█████████████████████████████| 20/20 [00:12<00:00,  1.59it/s]\n",
      "Epoch: 5. Train.      Loss: 0.091 | Accuracy: 0.991: 100%|█████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]\n",
      "Epoch: 5. Validation. Loss: 0.535 | Accuracy: 0.874: 100%|█████████████████████████████| 20/20 [00:12<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model = train_and_validate(model, arr_train, arr_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d90feb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(data_t[0]),type(data_t[1]))\n",
    "#print(type(arr[0]),type(arr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "479f2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(data_t[0][0]),type(data_t[0][1]))\n",
    "#print(type(arr[0][0]),type(arr[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63b4bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(data_t[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2362b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(arr[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8574f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(torchvision.transforms.functional.get_image_num_channels(data_t[0][0]),\n",
    "# torchvision.transforms.functional.get_image_num_channels(arr[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef61a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't pickle <function <lambda> at 0x00000247817AF0D0>: attribute lookup <lambda> on __main__ failed\n",
    "#model = train_and_validate(model, data_t, data_v, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675252c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3b99d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input are organized in [N, C, W, H]\n",
    "#model = train_and_validate(model, arr_train, arr_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2ef0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8ccd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0180ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torchvision.models.resnet18(pretrained= True)\n",
    "#model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "#model = model.to(params[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8087d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ValueError: In training mode, targets should be passed\n",
    "# output = model(image)\n",
    "# model = train_and_validate(model, arr_train, arr_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be15bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4832682",
   "metadata": {},
   "source": [
    "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12359b",
   "metadata": {},
   "source": [
    "### 5.1 Оптимизация(прунинг) ранее обученно модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa30e9",
   "metadata": {},
   "source": [
    "Проведем оптимизацию моделей двумя разными методами для сравнения ```L1FilterPruner``` и ```L2FilterPruner```, сохраним результаты пруненых моделей \"model_prunel1.pth\" и \"model_prunel2.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288621fe",
   "metadata": {},
   "source": [
    "**По задаче только L2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb898d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config_list = [{ 'sparsity': 0.5, \n",
    "#                'op_types': ['Conv2d'] \n",
    "#               }]\n",
    "#model = torch.load (\"./model.pth\", map_location=\"cpu\").eval()\n",
    "#dummy_input = torch.randn(1, 3, px, px).to(\"cpu\")\n",
    "#pruner = L1FilterPruner(model, config_list); #, dependency_aware=True, dummy_input=dummy_input);\n",
    "#pruned_model = pruner.compress();\n",
    "#pruner.export_model(model_path='./test.pt', mask_path='./test_mask.pt')\n",
    "#m = torch.load (\"./model.pth\", map_location=\"cpu\").eval()\n",
    "#m_speedup = ModelSpeedup(m, dummy_input, './test_mask.pt')\n",
    "#m_speedup.speedup_model();\n",
    "#torch.save(m, \"./model_prunel1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c35ce81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-29 00:15:55] INFO (nni.compression.pytorch.compressor/MainThread) Model state_dict saved to ./test.pt\n",
      "[2022-04-29 00:15:55] INFO (nni.compression.pytorch.compressor/MainThread) Mask dict saved to ./test_mask.pt\n",
      "[2022-04-29 00:15:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) start to speedup the model\n",
      "[2022-04-29 00:15:56] INFO (FixMaskConflict/MainThread) {'conv1': 1, 'layer1.0.conv1': 1, 'layer1.0.conv2': 1, 'layer1.1.conv1': 1, 'layer1.1.conv2': 1, 'layer2.0.conv1': 1, 'layer2.0.conv2': 1, 'layer2.0.downsample.0': 1, 'layer2.1.conv1': 1, 'layer2.1.conv2': 1, 'layer3.0.conv1': 1, 'layer3.0.conv2': 1, 'layer3.0.downsample.0': 1, 'layer3.1.conv1': 1, 'layer3.1.conv2': 1, 'layer4.0.conv1': 1, 'layer4.0.conv2': 1, 'layer4.0.downsample.0': 1, 'layer4.1.conv1': 1, 'layer4.1.conv2': 1}\n",
      "[2022-04-29 00:15:57] INFO (FixMaskConflict/MainThread) dim0 sparsity: 0.500000\n",
      "[2022-04-29 00:15:57] INFO (FixMaskConflict/MainThread) dim1 sparsity: 0.000000\n",
      "[2022-04-29 00:15:57] INFO (FixMaskConflict/MainThread) Dectected conv prune dim\" 0\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) infer module masks...\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for maxpool\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.aten::add_.61\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.aten::add_.62\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.downsample.0\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.downsample.1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.aten::add_.63\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.aten::add_.64\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.downsample.0\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.downsample.1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.aten::add_.65\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.aten::add_.66\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.downsample.0\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.downsample.1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.aten::add_.67\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.aten::add_.68\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for avgpool\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for .aten::flatten.60\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for fc\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the .aten::flatten.60\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the avgpool\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.relu.1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.aten::add_.68\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.conv2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.relu\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.bn1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.conv1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.relu.1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.aten::add_.67\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.bn2\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.downsample.1\n",
      "[2022-04-29 00:15:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.conv2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.downsample.0\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.relu.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.aten::add_.66\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.bn2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.conv2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.relu.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.aten::add_.65\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.bn2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.downsample.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.conv2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.downsample.0\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.relu.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.aten::add_.64\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.bn2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.conv2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.relu.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.aten::add_.63\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.bn2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.downsample.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.conv2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.downsample.0\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.relu.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.aten::add_.62\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.bn2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.conv2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.relu.1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.aten::add_.61\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.bn2\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.conv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the maxpool\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the relu\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the bn1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the conv1\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) resolve the mask conflict\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace compressed modules...\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 52\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: maxpool, op_type: MaxPool2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 32\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 52\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer1.0.aten::add_.61, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 32\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 52\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer1.1.aten::add_.62, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.downsample.0, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 64\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.downsample.1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 122\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 122\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer2.0.aten::add_.63, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 64\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 122\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer2.1.aten::add_.64, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.downsample.0, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 128\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.downsample.1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 238\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.relu, op_type: ReLU)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 238\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer3.0.aten::add_.65, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 128\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 238\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer3.1.aten::add_.66, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.downsample.0, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 256\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.downsample.1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 464\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 464\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer4.0.aten::add_.67, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.conv1, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 256\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.conv2, op_type: Conv2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 464\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer4.1.aten::add_.68, op_type: aten::add_) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.relu, op_type: ReLU)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: avgpool, op_type: AdaptiveAvgPool2d)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: .aten::flatten.60, op_type: aten::flatten) which is func type\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: fc, op_type: Linear)\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace linear with new in_features: 464, out_features: 10\n",
      "[2022-04-29 00:15:58] INFO (nni.compression.pytorch.speedup.compressor/MainThread) speedup done\n"
     ]
    }
   ],
   "source": [
    "config_list = [{ 'sparsity': 0.5, 'op_types': ['Conv2d'] }]\n",
    "model = torch.load (\"./model.pth\", map_location=\"cpu\").eval()\n",
    "dummy_input = torch.randn(1, 3, px, px).to(\"cpu\")\n",
    "pruner = L2FilterPruner(model, config_list) #, dependency_aware=True, dummy_input=dummy_input);\n",
    "pruned_model = pruner.compress();\n",
    "pruner.export_model(model_path='./test.pt', mask_path='./test_mask.pt')\n",
    "m = torch.load (\"./model.pth\", map_location=\"cpu\").eval()\n",
    "m_speedup = ModelSpeedup(m, dummy_input, './test_mask.pt')\n",
    "m_speedup.speedup_model();\n",
    "torch.save(m, \"./model_prunel2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad6e5d",
   "metadata": {},
   "source": [
    "### 5.2 Анализ результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485061c",
   "metadata": {},
   "source": [
    "Проведем анализ получившихся результатов по рамеру моделей и  скорости работы. Для этого создадим функцию оценки количества весов модели\n",
    "```get_n_params```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc77535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "805dd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_prunel1 = torch.load (\"./model_prunel1.pth\", map_location=\"cpu\").eval()\n",
    "model_prunel2 = torch.load (\"./model_prunel2.pth\", map_location=\"cpu\").eval()\n",
    "model = torch.load (\"./model.pth\", map_location=\"cpu\").eval()\n",
    "#dummy_input = torch.ones(128, 3, 32, 32).to(\"cpu\")  [64, 3, 7, 7]\n",
    "dummy_input = torch.ones(64, 3, 7, 7).to(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd0277b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11181642"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbf9d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_n_params(model_prunel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e5b8e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184546"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model_prunel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e356554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2pruning 46.37% parametr of original\n"
     ]
    }
   ],
   "source": [
    "#print (\"L1pruning {metric1}%, L2pruning {metric2}% parametr of original\".format( \\\n",
    "#                                    metric1=round(get_n_params(model_prunel1)/get_n_params(model)*100,2), \\\n",
    "#                                    metric2=round(get_n_params(model_prunel2)/get_n_params(model)*100,2)))\n",
    "print (\"L2pruning {metric2}% parametr of original\".format(metric2=round(get_n_params(model_prunel2)/get_n_params(model)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c539425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.2 ms ± 1.52 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54515018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#model_prunel1(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22ce5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.3 ms ± 1.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_prunel2(dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993997c",
   "metadata": {},
   "source": [
    "### 5.3 Дообучение пруниных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98d1c5",
   "metadata": {},
   "source": [
    "После прунинга точность моделей заметно уменьшается, поэтому требуется дообучение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8e118ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": 8,\n",
    "    \"epochs\": 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea1c3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_prunel1 = train_and_validate(model_prunel1.to(\"cpu\"), arr_train, arr_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ffcd783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_prunel2 = train_and_validate(model_prunel2.to(\"cuda\"), arr_train, arr_test, params)\n",
    "#AssertionError: Torch not compiled with CUDA enabled\n",
    "\n",
    "# conda install -c pytorch pytorch=1.2.0=py3.7_cuda92_cudnn7_1 \n",
    "# conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# устанавливала, не помогло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "91717dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 0.516 | Accuracy: 0.895: 100%|█████████████████████████████| 20/20 [00:25<00:00,  1.27s/it]\n",
      "Epoch: 1. Validation. Loss: 0.510 | Accuracy: 0.889: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Epoch: 2. Train.      Loss: 0.272 | Accuracy: 0.925: 100%|█████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n",
      "Epoch: 2. Validation. Loss: 0.482 | Accuracy: 0.876: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.75it/s]\n",
      "Epoch: 3. Train.      Loss: 0.166 | Accuracy: 0.953: 100%|█████████████████████████████| 20/20 [00:24<00:00,  1.23s/it]\n",
      "Epoch: 3. Validation. Loss: 0.478 | Accuracy: 0.873: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.75it/s]\n",
      "Epoch: 4. Train.      Loss: 0.104 | Accuracy: 0.973: 100%|█████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n",
      "Epoch: 4. Validation. Loss: 0.497 | Accuracy: 0.869: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n",
      "Epoch: 5. Train.      Loss: 0.061 | Accuracy: 0.988: 100%|█████████████████████████████| 20/20 [00:25<00:00,  1.28s/it]\n",
      "Epoch: 5. Validation. Loss: 0.509 | Accuracy: 0.871: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.73it/s]\n",
      "Epoch: 6. Train.      Loss: 0.036 | Accuracy: 0.994: 100%|█████████████████████████████| 20/20 [00:24<00:00,  1.22s/it]\n",
      "Epoch: 6. Validation. Loss: 0.536 | Accuracy: 0.869: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Epoch: 7. Train.      Loss: 0.021 | Accuracy: 0.997: 100%|█████████████████████████████| 20/20 [00:25<00:00,  1.25s/it]\n",
      "Epoch: 7. Validation. Loss: 0.562 | Accuracy: 0.869: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Epoch: 8. Train.      Loss: 0.015 | Accuracy: 0.999: 100%|█████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n",
      "Epoch: 8. Validation. Loss: 0.579 | Accuracy: 0.872: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Epoch: 9. Train.      Loss: 0.010 | Accuracy: 1.000: 100%|█████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n",
      "Epoch: 9. Validation. Loss: 0.590 | Accuracy: 0.875: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Epoch: 10. Train.      Loss: 0.008 | Accuracy: 1.000: 100%|████████████████████████████| 20/20 [00:25<00:00,  1.26s/it]\n",
      "Epoch: 10. Validation. Loss: 0.611 | Accuracy: 0.874: 100%|████████████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n",
      "Epoch: 11. Train.      Loss: 0.007 | Accuracy: 1.000: 100%|████████████████████████████| 20/20 [00:24<00:00,  1.24s/it]\n",
      "Epoch: 11. Validation. Loss: 0.625 | Accuracy: 0.874: 100%|████████████████████████████| 20/20 [00:11<00:00,  1.75it/s]\n",
      "Epoch: 12. Train.      Loss: 0.005 | Accuracy: 1.000: 100%|████████████████████████████| 20/20 [00:23<00:00,  1.19s/it]\n",
      "Epoch: 12. Validation. Loss: 0.637 | Accuracy: 0.874: 100%|████████████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Epoch: 13. Train.      Loss: 0.004 | Accuracy: 1.000: 100%|████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n",
      "Epoch: 13. Validation. Loss: 0.651 | Accuracy: 0.872: 100%|████████████████████████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Epoch: 14. Train.      Loss: 0.004 | Accuracy: 1.000: 100%|████████████████████████████| 20/20 [00:24<00:00,  1.20s/it]\n",
      "Epoch: 14. Validation. Loss: 0.662 | Accuracy: 0.872: 100%|████████████████████████████| 20/20 [00:11<00:00,  1.79it/s]\n",
      "Epoch: 15. Train.      Loss: 0.003 | Accuracy: 1.000: 100%|████████████████████████████| 20/20 [00:23<00:00,  1.18s/it]\n",
      "Epoch: 15. Validation. Loss: 0.662 | Accuracy: 0.874: 100%|████████████████████████████| 20/20 [00:11<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model_prunel2 = train_and_validate(model_prunel2.to(\"cpu\"), arr_train, arr_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf039e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34d27b2",
   "metadata": {},
   "source": [
    "Число весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "656abda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184546"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model_prunel2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555e16d",
   "metadata": {},
   "source": [
    "Время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "833c4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 ms ± 850 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_prunel2(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1289f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b36b6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_prunel2.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c228895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0a93184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000026BED889660>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prunel2.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87be1561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model_prunel2.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd0ecd4",
   "metadata": {},
   "source": [
    "Веса [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2dc76d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-9.7890e-03, -5.0687e-03, -1.2570e-03,  ...,  5.5386e-02,\n",
       "            1.5564e-02, -1.2600e-02],\n",
       "          [ 1.0369e-02,  9.8975e-03, -1.1004e-01,  ..., -2.7271e-01,\n",
       "           -1.3055e-01,  3.2204e-03],\n",
       "          [-7.2177e-03,  5.8775e-02,  2.9488e-01,  ...,  5.1752e-01,\n",
       "            2.5316e-01,  6.2023e-02],\n",
       "          ...,\n",
       "          [-2.6926e-02,  1.7066e-02,  7.3154e-02,  ..., -3.3308e-01,\n",
       "           -4.2170e-01, -2.5870e-01],\n",
       "          [ 3.0488e-02,  4.0612e-02,  6.2570e-02,  ...,  4.1319e-01,\n",
       "            3.9261e-01,  1.6574e-01],\n",
       "          [-1.3941e-02, -3.2089e-03, -2.4613e-02,  ..., -1.5259e-01,\n",
       "           -8.3408e-02, -7.9415e-03]],\n",
       "\n",
       "         [[-1.0284e-02, -2.5085e-02, -3.3558e-02,  ...,  3.1665e-02,\n",
       "           -4.7774e-05, -2.5233e-02],\n",
       "          [ 4.5777e-02,  3.4507e-02, -1.0396e-01,  ..., -3.1355e-01,\n",
       "           -1.6088e-01, -1.8309e-03],\n",
       "          [-2.6971e-04,  9.9565e-02,  4.0197e-01,  ...,  7.0684e-01,\n",
       "            3.6674e-01,  1.2343e-01],\n",
       "          ...,\n",
       "          [-5.4656e-02, -3.5933e-03,  2.8020e-02,  ..., -4.6149e-01,\n",
       "           -5.7121e-01, -3.6581e-01],\n",
       "          [ 3.3631e-02,  5.5711e-02,  9.9611e-02,  ...,  5.4651e-01,\n",
       "            4.8249e-01,  1.9952e-01],\n",
       "          [ 5.9734e-03,  7.7816e-03, -1.7322e-02,  ..., -1.4943e-01,\n",
       "           -7.7873e-02, -1.0614e-03]],\n",
       "\n",
       "         [[-3.7384e-04, -6.9792e-03,  2.3143e-02,  ...,  8.9441e-02,\n",
       "            3.3851e-02, -1.8315e-02],\n",
       "          [ 1.5568e-02, -1.7787e-02, -1.2495e-01,  ..., -2.5411e-01,\n",
       "           -1.2937e-01, -2.8646e-02],\n",
       "          [ 1.0687e-02,  5.0271e-02,  2.1741e-01,  ...,  3.4877e-01,\n",
       "            1.0286e-01,  1.7782e-02],\n",
       "          ...,\n",
       "          [-2.7727e-02,  1.9114e-02,  9.8991e-02,  ..., -1.1786e-01,\n",
       "           -2.5821e-01, -1.5481e-01],\n",
       "          [ 2.0478e-02, -2.9528e-03, -3.8121e-02,  ...,  2.4196e-01,\n",
       "            2.4357e-01,  1.1851e-01],\n",
       "          [ 7.2038e-04,  1.5387e-03, -1.0194e-02,  ..., -1.4906e-01,\n",
       "           -1.1768e-01, -3.9449e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.0290e-02, -1.9179e-02, -1.1228e-02,  ...,  4.6578e-03,\n",
       "           -1.2446e-02, -1.0015e-02],\n",
       "          [-2.8261e-02, -2.7876e-02, -3.4324e-03,  ..., -7.4766e-02,\n",
       "           -6.7031e-02, -1.8219e-02],\n",
       "          [-3.4124e-02, -1.7615e-02, -2.5117e-02,  ..., -1.4096e-01,\n",
       "           -1.4509e-01, -3.0454e-02],\n",
       "          ...,\n",
       "          [-3.6578e-02, -1.0159e-02, -8.9743e-03,  ..., -2.2069e-02,\n",
       "           -5.7084e-02,  7.5135e-03],\n",
       "          [-6.3648e-03,  2.1030e-02,  6.1931e-03,  ...,  1.9023e-02,\n",
       "           -8.0779e-03,  1.2169e-02],\n",
       "          [-1.5233e-02,  1.4143e-03, -2.0924e-02,  ...,  6.4805e-04,\n",
       "           -1.5411e-02, -2.1643e-03]],\n",
       "\n",
       "         [[ 2.1602e-02,  1.7168e-03,  1.0022e-02,  ...,  2.4940e-02,\n",
       "            1.4430e-02,  2.0119e-02],\n",
       "          [ 3.1954e-02,  2.0498e-02,  2.7046e-02,  ..., -7.3143e-02,\n",
       "           -4.6324e-02,  2.7375e-02],\n",
       "          [ 1.8561e-02,  2.7669e-02, -7.9384e-03,  ..., -1.6965e-01,\n",
       "           -1.5241e-01, -3.8963e-03],\n",
       "          ...,\n",
       "          [ 8.2154e-03,  1.6563e-02, -4.5239e-03,  ..., -4.9568e-02,\n",
       "           -6.4912e-02,  3.5951e-02],\n",
       "          [ 3.3568e-02,  3.9903e-02,  1.0473e-02,  ...,  1.4441e-02,\n",
       "            8.9125e-03,  5.6819e-02],\n",
       "          [ 2.9462e-02,  3.1483e-02,  1.9364e-03,  ...,  1.4791e-02,\n",
       "            1.8018e-02,  4.4618e-02]],\n",
       "\n",
       "         [[-5.0806e-02, -3.3210e-02, -7.0388e-03,  ...,  5.4904e-02,\n",
       "            4.2022e-02,  1.3740e-02],\n",
       "          [-5.8956e-03,  2.1787e-02,  5.4940e-02,  ...,  8.1189e-03,\n",
       "            3.3669e-02,  7.3733e-02],\n",
       "          [-8.9309e-03,  2.7982e-02,  1.6755e-02,  ..., -9.4579e-02,\n",
       "           -8.1484e-02,  3.4414e-02],\n",
       "          ...,\n",
       "          [-1.5927e-02,  6.9891e-03, -4.8524e-03,  ..., -2.0962e-02,\n",
       "           -3.9023e-02,  4.6040e-02],\n",
       "          [-1.9725e-02, -4.8894e-04, -1.6986e-02,  ...,  3.3949e-03,\n",
       "           -2.1098e-03,  4.0839e-02],\n",
       "          [-2.5249e-02, -7.5555e-03, -2.6954e-02,  ...,  7.8713e-03,\n",
       "            1.1187e-02,  3.1824e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.5984e-02,  4.8316e-02,  2.2540e-02,  ..., -6.1791e-02,\n",
       "           -2.7904e-02, -8.3526e-03],\n",
       "          [ 5.3305e-02,  1.7301e-01,  9.7419e-02,  ..., -1.8308e-01,\n",
       "           -1.2247e-01, -7.9848e-02],\n",
       "          [ 4.7549e-02,  2.7072e-01,  1.8253e-01,  ..., -2.6769e-01,\n",
       "           -2.2076e-01, -1.4563e-01],\n",
       "          ...,\n",
       "          [ 1.2002e-02,  3.4273e-01,  4.1453e-01,  ..., -2.7092e-01,\n",
       "           -3.3067e-01, -2.3745e-01],\n",
       "          [-2.0981e-02,  2.4234e-01,  3.5337e-01,  ..., -1.4296e-01,\n",
       "           -2.2522e-01, -1.9870e-01],\n",
       "          [-2.7331e-02,  1.6835e-01,  2.4211e-01,  ..., -4.9403e-02,\n",
       "           -1.1235e-01, -1.6127e-01]],\n",
       "\n",
       "         [[-2.5482e-03, -3.9213e-02, -4.5428e-03,  ...,  3.4563e-02,\n",
       "            2.4611e-02,  1.2688e-02],\n",
       "          [-4.4317e-03, -2.4513e-02, -2.3291e-02,  ...,  9.6917e-03,\n",
       "            4.0312e-02,  2.9734e-02],\n",
       "          [-1.1061e-02, -2.6372e-02, -4.9838e-02,  ...,  1.6629e-02,\n",
       "            3.8627e-02,  2.2011e-02],\n",
       "          ...,\n",
       "          [-4.3367e-03, -5.3957e-02, -2.4762e-02,  ...,  3.9107e-02,\n",
       "            1.3151e-03,  2.7575e-02],\n",
       "          [ 1.7423e-02, -6.4517e-02, -3.6032e-02,  ...,  2.6709e-02,\n",
       "            1.3396e-02,  3.5043e-02],\n",
       "          [ 9.2546e-03, -4.8944e-02, -4.7719e-02,  ..., -5.0805e-03,\n",
       "            1.2696e-02,  2.7590e-02]],\n",
       "\n",
       "         [[ 2.0183e-02, -4.1159e-02, -8.0691e-03,  ...,  3.8765e-02,\n",
       "           -1.1640e-02, -8.9217e-05],\n",
       "          [-1.6587e-02, -1.1902e-01, -8.7209e-02,  ...,  1.0198e-01,\n",
       "            1.3437e-01,  9.7807e-02],\n",
       "          [-5.5713e-02, -2.0063e-01, -1.8986e-01,  ...,  1.9125e-01,\n",
       "            2.0267e-01,  1.1201e-01],\n",
       "          ...,\n",
       "          [-1.2516e-02, -2.9131e-01, -3.1270e-01,  ...,  2.4654e-01,\n",
       "            2.6915e-01,  2.1933e-01],\n",
       "          [ 4.0897e-02, -2.1923e-01, -2.7454e-01,  ...,  1.2226e-01,\n",
       "            1.8196e-01,  2.0918e-01],\n",
       "          [ 4.8999e-02, -1.3268e-01, -1.8635e-01,  ...,  4.2812e-03,\n",
       "            8.4850e-02,  1.5584e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 8.5798e-03, -1.1238e-02, -3.5873e-02,  ..., -1.0290e-02,\n",
       "            4.9392e-03,  9.0089e-03],\n",
       "          [-8.5437e-02, -9.0102e-02, -3.7847e-03,  ...,  4.0063e-02,\n",
       "            1.6951e-02, -1.1046e-02],\n",
       "          [-3.9193e-02,  8.5491e-02,  2.5859e-01,  ...,  5.2723e-02,\n",
       "           -6.9808e-03, -4.5055e-02],\n",
       "          ...,\n",
       "          [ 1.2832e-01,  3.2875e-02, -2.9331e-01,  ..., -1.6054e-01,\n",
       "            1.0811e-01,  5.6465e-02],\n",
       "          [-4.6785e-02, -2.1141e-01, -2.6013e-01,  ...,  2.4812e-01,\n",
       "            1.3642e-01,  8.7430e-03],\n",
       "          [-5.5236e-02,  2.8271e-03,  1.0303e-01,  ...,  1.0039e-01,\n",
       "           -4.4504e-02, -7.4617e-02]],\n",
       "\n",
       "         [[-3.9921e-05,  1.5927e-02,  7.4326e-03,  ...,  5.0297e-03,\n",
       "            2.4315e-03, -9.0342e-03],\n",
       "          [-4.8286e-02, -1.8696e-02,  7.6601e-02,  ...,  6.6240e-02,\n",
       "            1.1142e-02, -2.1199e-02],\n",
       "          [ 2.6993e-02,  1.9462e-01,  3.6521e-01,  ...,  3.4184e-03,\n",
       "           -8.1599e-02, -7.9009e-02],\n",
       "          ...,\n",
       "          [ 1.4098e-01, -1.3467e-02, -4.9256e-01,  ..., -2.8467e-01,\n",
       "            1.1495e-01,  1.0962e-01],\n",
       "          [-1.2729e-01, -3.4489e-01, -4.2813e-01,  ...,  3.2280e-01,\n",
       "            2.2606e-01,  6.7396e-02],\n",
       "          [-1.0345e-01, -1.0347e-02,  1.3522e-01,  ...,  2.6247e-01,\n",
       "            6.8359e-02, -2.5743e-02]],\n",
       "\n",
       "         [[ 2.5489e-02,  2.4824e-02,  1.0144e-02,  ..., -8.9792e-03,\n",
       "           -1.2645e-03, -4.5316e-03],\n",
       "          [-1.9481e-02, -4.6971e-02, -1.9685e-02,  ...,  2.0462e-02,\n",
       "            9.0941e-04, -4.5322e-03],\n",
       "          [-2.4419e-02,  4.5735e-02,  1.5622e-01,  ...,  4.1827e-02,\n",
       "           -2.0051e-02, -2.1080e-02],\n",
       "          ...,\n",
       "          [ 7.4263e-02,  3.5728e-02, -2.2991e-01,  ..., -8.9681e-02,\n",
       "            8.3274e-02,  5.5882e-02],\n",
       "          [-6.6430e-02, -1.8204e-01, -2.1851e-01,  ...,  2.1752e-01,\n",
       "            7.7659e-02,  7.3901e-03],\n",
       "          [-5.8444e-02,  1.9405e-02,  1.0114e-01,  ...,  1.0943e-01,\n",
       "           -2.7388e-03, -3.9947e-03]]],\n",
       "\n",
       "\n",
       "        [[[-8.0904e-03,  2.0677e-02,  3.2393e-02,  ...,  2.8180e-02,\n",
       "            1.1928e-02,  1.7447e-02],\n",
       "          [ 6.7649e-03, -3.5113e-02, -3.8331e-02,  ...,  7.1342e-02,\n",
       "            4.3787e-02,  5.1298e-02],\n",
       "          [-3.8508e-02, -1.2250e-01, -1.3988e-01,  ...,  3.2386e-02,\n",
       "            3.5554e-02,  2.4425e-02],\n",
       "          ...,\n",
       "          [ 1.3240e-02,  8.9728e-04, -1.1481e-02,  ...,  1.2125e-03,\n",
       "            1.6571e-02,  1.2892e-02],\n",
       "          [-3.0603e-03,  1.3518e-02,  1.4224e-02,  ...,  1.3591e-03,\n",
       "            1.9956e-02, -2.1516e-03],\n",
       "          [ 3.7662e-03,  2.4936e-02,  1.1291e-02,  ...,  5.4029e-03,\n",
       "            1.6462e-02,  1.3878e-02]],\n",
       "\n",
       "         [[-1.2339e-02,  3.7924e-04,  6.6603e-03,  ..., -6.5768e-03,\n",
       "            8.7143e-03,  1.5089e-02],\n",
       "          [-1.8076e-02, -6.7779e-02, -7.1912e-02,  ...,  2.9168e-02,\n",
       "            2.5126e-02,  2.3520e-02],\n",
       "          [-5.5001e-02, -1.4790e-01, -1.6181e-01,  ...,  1.0902e-02,\n",
       "            3.1892e-02,  1.0781e-02],\n",
       "          ...,\n",
       "          [-2.2171e-03, -2.0014e-02, -2.2372e-02,  ..., -5.9727e-03,\n",
       "            2.3520e-02,  1.0137e-02],\n",
       "          [-1.7739e-03,  9.9164e-03,  2.2422e-02,  ...,  3.3473e-03,\n",
       "            3.6987e-02,  7.0035e-03],\n",
       "          [-8.7250e-03,  5.8323e-03,  3.7269e-03,  ..., -9.7427e-03,\n",
       "            2.5581e-02,  1.6036e-02]],\n",
       "\n",
       "         [[ 2.1472e-03, -3.2340e-03,  1.7307e-03,  ..., -4.7873e-02,\n",
       "           -2.5103e-02, -2.3092e-02],\n",
       "          [ 1.2210e-03, -4.9160e-02, -5.9704e-02,  ..., -1.6811e-02,\n",
       "           -2.2820e-02, -3.6318e-02],\n",
       "          [-2.2442e-02, -9.9183e-02, -1.1008e-01,  ..., -1.1332e-02,\n",
       "           -7.9701e-03, -4.0477e-02],\n",
       "          ...,\n",
       "          [ 8.5056e-03, -9.2380e-03, -3.3827e-03,  ..., -3.5199e-02,\n",
       "           -9.0343e-03, -2.5408e-02],\n",
       "          [ 2.6912e-03, -1.5424e-04,  1.8779e-02,  ..., -2.4140e-02,\n",
       "            1.3663e-02, -1.6664e-02],\n",
       "          [-1.9354e-02, -2.9061e-02, -2.3468e-02,  ..., -4.9922e-02,\n",
       "           -1.3988e-02, -2.5818e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.7216e-02,  7.1508e-03,  1.9523e-02,  ...,  1.8371e-02,\n",
       "            1.4797e-02, -1.7451e-02],\n",
       "          [-1.0716e-02,  8.6035e-02,  1.2691e-01,  ...,  1.3501e-02,\n",
       "            5.4070e-04, -2.9733e-02],\n",
       "          [ 1.1332e-01,  1.8681e-01,  5.1458e-02,  ..., -1.7246e-01,\n",
       "           -7.1330e-02, -6.1143e-02],\n",
       "          ...,\n",
       "          [-5.2435e-02, -2.5661e-01, -2.6691e-01,  ...,  2.6848e-01,\n",
       "            1.4511e-01,  5.5729e-02],\n",
       "          [-2.0413e-02, -2.9201e-02,  1.0327e-01,  ...,  2.0945e-01,\n",
       "           -3.2779e-03, -3.7311e-02],\n",
       "          [-2.2166e-02,  1.2586e-02,  8.5002e-02,  ..., -4.4914e-02,\n",
       "           -1.4593e-01, -8.9920e-02]],\n",
       "\n",
       "         [[-6.6456e-03,  3.2507e-02,  1.5334e-02,  ..., -8.7908e-03,\n",
       "            2.8901e-03,  1.0112e-03],\n",
       "          [ 6.1208e-02,  1.4853e-01,  1.4615e-01,  ..., -2.9317e-02,\n",
       "           -2.0245e-02, -9.2102e-03],\n",
       "          [ 1.6087e-01,  2.0906e-01, -2.5207e-02,  ..., -2.7213e-01,\n",
       "           -1.0699e-01, -6.1861e-02],\n",
       "          ...,\n",
       "          [-1.3666e-01, -4.0772e-01, -3.8522e-01,  ...,  4.0861e-01,\n",
       "            2.6353e-01,  1.3613e-01],\n",
       "          [-5.9140e-02, -6.1178e-02,  1.4197e-01,  ...,  3.5823e-01,\n",
       "            9.0982e-02, -1.4992e-03],\n",
       "          [ 7.0966e-03,  5.7897e-02,  1.5362e-01,  ...,  4.7486e-02,\n",
       "           -9.9952e-02, -9.7540e-02]],\n",
       "\n",
       "         [[-6.7158e-03,  1.3124e-02, -2.6428e-02,  ...,  3.4515e-03,\n",
       "            1.8573e-03,  1.3985e-02],\n",
       "          [ 5.9453e-03,  4.4807e-02,  5.9805e-02,  ...,  1.3563e-02,\n",
       "           -4.9442e-03,  3.5751e-03],\n",
       "          [ 5.4367e-02,  1.2404e-01,  4.3331e-02,  ..., -1.4508e-01,\n",
       "           -7.4563e-02, -5.6902e-02],\n",
       "          ...,\n",
       "          [-3.1513e-02, -1.6291e-01, -1.5828e-01,  ...,  2.2847e-01,\n",
       "            1.2106e-01,  7.2910e-02],\n",
       "          [-1.0608e-02, -1.6468e-03,  8.4120e-02,  ...,  1.5728e-01,\n",
       "            2.2040e-02, -9.9610e-03],\n",
       "          [-5.8716e-03, -5.9770e-03,  3.6004e-02,  ..., -2.4648e-02,\n",
       "           -7.0905e-02, -6.6591e-02]]]], requires_grad=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_prunel2.parameters())[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
